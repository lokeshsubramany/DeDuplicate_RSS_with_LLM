{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "    }\n",
    "\n",
    "def get_feed_articles_df(feedname,url):\n",
    "    \"\"\"\n",
    "    Get article titles and create a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        feedname (str): Name of the feed.\n",
    "        url (str): URL of the XML feed.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing article titles and feed name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = requests.get(url, headers=headers)\n",
    "\n",
    "        soup = BeautifulSoup(result.text, \"xml\")        \n",
    "        article_urls = [i.text for i in soup.findAll('link')]\n",
    "\n",
    "        #The verge has the links in the id tag, if the list is empty with the link tag, try the id tag\n",
    "        if len([item for item in article_urls if bool(item)])  == 0: \n",
    "            article_urls = [i.text for i in soup.findAll('id')]      \n",
    "        \n",
    "       \n",
    "        #Parse it as html to get the links correctly, other wise In some websites, <media:title> is also returned as a link\n",
    "        soup = BeautifulSoup(result.text, \"html.parser\")\n",
    "        article_titles = [i.text for i in soup.findAll('title')]      \n",
    "        \n",
    "        df = pd.DataFrame({'Article_title': article_titles, 'Article_URL': article_urls[-len(article_titles):], 'Feedname': feedname})\n",
    "        \n",
    "        #Remove homepage from url list and empty url rows\n",
    "        homepage = url.split('.com')[0] + '.com/'\n",
    "        df = df[(df['Article_URL'] != homepage) & (df['Article_URL'] != '') ]        \n",
    "        \n",
    "        # Drop duplicate URLs\n",
    "        df = df.drop_duplicates(subset=['Article_URL'], keep='first')\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error getting feed: \", e)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_name = 'RssFeeds.db'\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"\n",
    "    Establish a connection to a SQLite database.\n",
    "    \n",
    "    Args:\n",
    "        db_name (str): Name of the SQLite database file.\n",
    "    \n",
    "    Returns:\n",
    "        sqlite3.Connection: Connection object to the SQLite database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        con = sqlite3.connect(db_name)\n",
    "        return con\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error connecting to database: \", e)\n",
    "        return None\n",
    "\n",
    "def create_db():\n",
    "    \"\"\"\n",
    "    Create a new SQLite database and execute the given query to create tables.\n",
    "    \n",
    "    Args:\n",
    "        db_name (str): Name of the SQLite database file.\n",
    "        query (str): SQL query to create tables in the database.\n",
    "    \n",
    "    Returns:\n",
    "        sqlite3.Connection: Connection object to the SQLite database.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"CREATE TABLE IF NOT EXISTS FEEDS( Feedname, Article_title UNIQUE, Article_URL, Duplicate, Date, Summary)\"    \n",
    "\n",
    "    con = get_connection()\n",
    "    \n",
    "    if con is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(query)\n",
    "        con.commit()\n",
    "        #return con\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error creating database: \", e)\n",
    "        con.close()\n",
    "        #return None\n",
    "    \n",
    "    print(\"DB created successfully\")\n",
    "\n",
    "def insert_to_db(data, query):\n",
    "    \"\"\"\n",
    "    Insert data into SQLite database using executemany.\n",
    "    \n",
    "    Args:\n",
    "        con (sqlite3.Connection): Connection object to the SQLite database.\n",
    "        data (list of tuples): Data to be inserted into the database.\n",
    "        query (str): SQL query for insertion.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    con = get_connection()\n",
    "\n",
    "    if not data:\n",
    "        print(\"No data to insert.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.executemany(query, data)\n",
    "        con.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting data into database: \", e)\n",
    "        con.rollback()\n",
    "\n",
    "def insert_to_FEEDS(data):\n",
    "    con = get_connection()\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(\"No data to insert.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "\n",
    "        query = \"INSERT Or REPLACE INTO FEEDS(Article_title,Article_URL,Feedname) VALUES (?, ?, ?)\"\n",
    "\n",
    "        cur.executemany(query, data)\n",
    "        con.commit()\n",
    "        con.close()\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error inserting data into database: \", e)\n",
    "        con.rollback()\n",
    "        con.close()\n",
    "\n",
    "def delete_from_db(tablename):\n",
    "    \"\"\"\n",
    "    Delete data from SQLite database.\n",
    "    \n",
    "    Args:\n",
    "        con (sqlite3.Connection): Connection object to the SQLite database.\n",
    "        query (str): SQL query for deletion.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    con = get_connection()\n",
    "    query = \"DROP TABLE IF EXISTS \" + tablename\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(query)\n",
    "        con.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error deleting data from database: \", e)\n",
    "        con.rollback()\n",
    "\n",
    "\n",
    "def query_db( query):\n",
    "    \"\"\"\n",
    "    Execute a SQL query and fetch results from SQLite database.\n",
    "    \n",
    "    Args:\n",
    "        con (sqlite3.Connection): Connection object to the SQLite database.\n",
    "        query (str): SQL query to be executed.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Result set fetched from the database.\n",
    "    \"\"\"\n",
    "    con = get_connection()\n",
    "\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(query)\n",
    "        return cur.fetchall()\n",
    "    except sqlite3.Error as e:\n",
    "        print(\"Error executing query: \", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedlist={'Engadget':'https://www.engadget.com/rss.xml', \n",
    "          'The Verge':'https://www.theverge.com/rss/index.xml',\n",
    "          'Techcrunch':'https://techcrunch.com/feed/',\n",
    "          'Ars Technica':'https://feeds.arstechnica.com/arstechnica/index',\n",
    "          'Jalopnik':'https://jalopnik.com/rss'}  \n",
    "\n",
    "def refresh_feeds():\n",
    "    for feed in feedlist:\n",
    "        print('Getting and inserting data for ', feed)\n",
    "        df = get_feed_articles_df(feed,feedlist[feed])  \n",
    "        insert_to_FEEDS(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB created successfully\n"
     ]
    }
   ],
   "source": [
    "create_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and inserting data for  Engadget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lokes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\html\\parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and inserting data for  The Verge\n",
      "Getting and inserting data for  Techcrunch\n",
      "Getting and inserting data for  Ars Technica\n",
      "Getting and inserting data for  Jalopnik\n"
     ]
    }
   ],
   "source": [
    "refresh_feeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedname</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Article_URL</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Date</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engadget</td>\n",
       "      <td>Marvelâs making an âinteractive storyâ b...</td>\n",
       "      <td>https://www.engadget.com/marvels-making-an-int...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engadget</td>\n",
       "      <td>Ugh, Max subscription prices might be going up...</td>\n",
       "      <td>https://www.engadget.com/ugh-max-subscription-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engadget</td>\n",
       "      <td>Oh no, I think I want an iPad Pro now</td>\n",
       "      <td>https://www.engadget.com/oh-no-i-think-i-want-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engadget</td>\n",
       "      <td>Nintendo just revealed a NES speedrunning coll...</td>\n",
       "      <td>https://www.engadget.com/nintendo-just-reveale...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engadget</td>\n",
       "      <td>The Google Pixel Watch 2 has never been cheaper</td>\n",
       "      <td>https://www.engadget.com/the-google-pixel-watc...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Jalopnik</td>\n",
       "      <td>The 2024 BMW F900GS Has No Worlds Left To Conquer</td>\n",
       "      <td>https://jalopnik.com/the-2024-bmw-f900gs-has-n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Jalopnik</td>\n",
       "      <td>The Incredible Tale Of 1907's 8,000-Mile Race ...</td>\n",
       "      <td>https://jalopnik.com/the-incredible-tale-of-19...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Jalopnik</td>\n",
       "      <td>Bear Drags Crash Victim From Wreckage After Ca...</td>\n",
       "      <td>https://jalopnik.com/bear-drags-crash-victim-f...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Jalopnik</td>\n",
       "      <td>At $5,000, Is This 1981 Mercury Marquis A Libe...</td>\n",
       "      <td>https://jalopnik.com/at-5-000-is-this-1981-mer...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Jalopnik</td>\n",
       "      <td>NASA Director Says He Trusts SpaceX Because El...</td>\n",
       "      <td>https://jalopnik.com/nasa-director-says-he-tru...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feedname                                      Article_title  \\\n",
       "0    Engadget  Marvelâs making an âinteractive storyâ b...   \n",
       "1    Engadget  Ugh, Max subscription prices might be going up...   \n",
       "2    Engadget              Oh no, I think I want an iPad Pro now   \n",
       "3    Engadget  Nintendo just revealed a NES speedrunning coll...   \n",
       "4    Engadget    The Google Pixel Watch 2 has never been cheaper   \n",
       "..        ...                                                ...   \n",
       "148  Jalopnik  The 2024 BMW F900GS Has No Worlds Left To Conquer   \n",
       "149  Jalopnik  The Incredible Tale Of 1907's 8,000-Mile Race ...   \n",
       "150  Jalopnik  Bear Drags Crash Victim From Wreckage After Ca...   \n",
       "151  Jalopnik  At $5,000, Is This 1981 Mercury Marquis A Libe...   \n",
       "152  Jalopnik  NASA Director Says He Trusts SpaceX Because El...   \n",
       "\n",
       "                                           Article_URL Duplicate  Date Summary  \n",
       "0    https://www.engadget.com/marvels-making-an-int...      None  None    None  \n",
       "1    https://www.engadget.com/ugh-max-subscription-...      None  None    None  \n",
       "2    https://www.engadget.com/oh-no-i-think-i-want-...      None  None    None  \n",
       "3    https://www.engadget.com/nintendo-just-reveale...      None  None    None  \n",
       "4    https://www.engadget.com/the-google-pixel-watc...      None  None    None  \n",
       "..                                                 ...       ...   ...     ...  \n",
       "148  https://jalopnik.com/the-2024-bmw-f900gs-has-n...      None  None    None  \n",
       "149  https://jalopnik.com/the-incredible-tale-of-19...      None  None    None  \n",
       "150  https://jalopnik.com/bear-drags-crash-victim-f...      None  None    None  \n",
       "151  https://jalopnik.com/at-5-000-is-this-1981-mer...      None  None    None  \n",
       "152  https://jalopnik.com/nasa-director-says-he-tru...      None  None    None  \n",
       "\n",
       "[153 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query_db(\"Select * from FEEDS\")\n",
    "pd.read_sql(\"Select * from FEEDS\", get_connection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
